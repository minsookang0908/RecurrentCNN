{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "class LRN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRN, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        div = x.pow(2).unsqueeze(1)\n",
    "        self.alpha = 0.001\n",
    "        self.beta = 0.75\n",
    "\n",
    "        kernel_size = x.size(1)//8 + 1\n",
    "        padding_size = (kernel_size-1)//2\n",
    "        average = nn.AvgPool3d(kernel_size = (kernel_size,1,1),\n",
    "                              stride = 1,\n",
    "                              padding = (padding_size,0,0))\n",
    "        div = average(div).squeeze(1)\n",
    "        div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        out = x.div(div)\n",
    "        return out\n",
    "class RCL_block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RCL_block,self).__init__()\n",
    "        self.feedconv = nn.Conv2d(96,96, kernel_size = 3,\n",
    "                            padding =1)\n",
    "        self.reconv = nn.Conv2d(96,96, kernel_size = 3,\n",
    "                               padding =1,bias = False)\n",
    "    def forward(self, *args):\n",
    "\n",
    "        for i,num in enumerate(args):\n",
    "            if i == 0:\n",
    "                u0 = num\n",
    "            elif i == 1:\n",
    "                u1 = num\n",
    "            elif i == 2:\n",
    "                u2 = num\n",
    "            else:\n",
    "                u3 = num\n",
    "\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            conv0 = self.feedconv(u0)\n",
    "            x0 = nn.ReLU().forward(conv0)\n",
    "            x0 = LRN().forward(x0)\n",
    "            x1 = conv0 + self.reconv(x0)\n",
    "            x1 = nn.ReLU().forward(x1)\n",
    "            x1 = LRN().forward(x1)\n",
    "            x2 = conv0 + self.reconv(x1)\n",
    "            x2 = nn.ReLU().forward(x2)\n",
    "            x2 = LRN().forward(x2)\n",
    "            x3 = conv0 + self.reconv(x2)\n",
    "            x3 = nn.ReLU().forward(x3)\n",
    "            x3 = LRN().forward(x3)\n",
    "            return x0,x1,x2,x3\n",
    "        else:\n",
    "\n",
    "            x0 = self.feedconv(u0)\n",
    "            x0 = nn.ReLU()(x0)\n",
    "            x0 = LRN()(x0)\n",
    "            x1 = self.feedconv(u1) + self.reconv(x0)\n",
    "            x1 = nn.ReLU().forward(x1)\n",
    "            x1 = LRN()(x1)\n",
    "            x2 = self.feedconv(u2) + self.reconv(x1)\n",
    "            x2 = nn.ReLU()(x2)\n",
    "            x2 = LRN()(x2)\n",
    "            x3 = self.feedconv(u3) + self.reconv(x2)\n",
    "            x3 = nn.ReLU()(x3)\n",
    "            x3 = LRN()(x3)\n",
    "            return x0,x1,x2,x3\n",
    "\n",
    "\n",
    "\n",
    "class RCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RCNN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(3,96, kernel_size = 5, padding =2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(3, stride =2, padding=1))\n",
    "        self.layer2 = RCL_block()\n",
    "\n",
    "        self.layer3 = RCL_block()\n",
    "        self.maxpool = nn.MaxPool2d(3, stride =2, padding=1)\n",
    "        self.layer4 = RCL_block()\n",
    "        self.layer5 = RCL_block()\n",
    "        self.globalpool = nn.MaxPool2d(8)\n",
    "        self.fc = nn.Linear(96*1,100)\n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)\n",
    "        conv1 = LRN()(conv1)       # print conv1.data.size()\n",
    "        x20, x21, x22, x23 = self.layer2(conv1)\n",
    "        #x20, x21, x22, x23 = self.layer2(conv1)\n",
    "        x20 = nn.Dropout2d(p=0.2)(x20)\n",
    "        x21 = nn.Dropout2d(p=0.2)(x21)\n",
    "        x22 = nn.Dropout2d(p=0.2)(x22)\n",
    "        x23 = nn.Dropout2d(p=0.2)(x23)\n",
    "        x30, x31, x32, x33 = self.layer3(x20, x21, x22, x23)\n",
    "        x33 = self.maxpool(x33)\n",
    "        x32 = self.maxpool(x32)\n",
    "        x31 = self.maxpool(x31)\n",
    "        x30 = self.maxpool(x30)\n",
    "        x33 = nn.Dropout2d(p=0.2)(x33)\n",
    "        x32 = nn.Dropout2d(p=0.2)(x32)\n",
    "        x31 = nn.Dropout2d(p=0.2)(x31)\n",
    "        x30 = nn.Dropout2d(p=0.2)(x30)\n",
    "        x40, x41, x42, x43 = self.layer4(x30,x31,x32,x33)\n",
    "        x40 = nn.Dropout2d(p=0.2)(x40)\n",
    "        x41 = nn.Dropout2d(p=0.2)(x41)\n",
    "        x42 = nn.Dropout2d(p=0.2)(x42)\n",
    "        x43 = nn.Dropout2d(p=0.2)(x43)\n",
    "        x50, x51, x52, x53 = self.layer5(x40, x41, x42, x43)\n",
    "       # x6 = torch.cat((x50,x51,x52,x53),1)\n",
    "\n",
    "        out = self.globalpool(x53)\n",
    "\n",
    "        out = out.view(-1, 96*1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.01\n",
    "    num_epochs = 75\n",
    "    #transform = transforms.ToTensor()\n",
    "  #  transform = transforms.Compose([transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "    train_dataset = datasets.CIFAR100(\n",
    "        root = './data',\n",
    "        train = True,\n",
    "        download = True,\n",
    "        )\n",
    "    mean_r = train_dataset.train_data[:,:,:,0].mean()/255\n",
    "    mean_g = train_dataset.train_data[:,:,:,1].mean()/255\n",
    "    mean_b = train_dataset.train_data[:,:,:,2].mean()/255\n",
    "  #  print mean_r, mean_g, mean_b\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((mean_r,mean_g,mean_b),(1,1,1))])\n",
    "    train_dataset = datasets.CIFAR100(\n",
    "         root = './data',\n",
    "         train = True,\n",
    "         download = False,\n",
    "         transform = transform)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = True,\n",
    "                         num_workers = 2)\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean_r,mean_g,mean_b),(1,1,1))])\n",
    "    test_dataset = datasets.CIFAR100(\n",
    "    root = './data',\n",
    "        train = False,\n",
    "        download = True,\n",
    "        transform = transform)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                        batch_size = batch_size,\n",
    "                        shuffle = False,\n",
    "                        num_workers = 2)\n",
    "\n",
    "\n",
    "    rcnn = RCNN()\n",
    "    rcnn.cuda()\n",
    "    rcnn.train()\n",
    "    #valid_set = torch.cuda.FloatTensor(100,3,32,32)\n",
    "    #valid_set = Variable(valid_set)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(rcnn.parameters(), lr = learning_rate, momentum = 0.9,weight_decay = 1e-4,nesterov = True)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer ,mode = 'max',patience = 3, verbose = True,  min_lr =0.01*1/1000)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        num = 0\n",
    "        total_valid = 0\n",
    "        correct_valid = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            rcnn.train()\n",
    "            images = Variable(images).cuda()\n",
    "\n",
    "        #   label = labels\n",
    "            labels = Variable(labels).cuda()\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = rcnn.forward(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i >399:\n",
    "                valid_images = images\n",
    "                valid_label = labels.cpu().data\n",
    "                total_valid = total_valid + valid_label.size(0)\n",
    "                rcnn.eval()\n",
    "                valid_out = rcnn(valid_images)\n",
    "                _, valid_predicted = torch.max(valid_out.data,1)\n",
    "                correct_valid += (valid_predicted.cpu() == valid_label).sum()\n",
    "            if (i+1) % 100 == 0:\n",
    "                num = num + 1\n",
    "          # print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                  # %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "        #scheduler.step(loss.data[0])\n",
    "                print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "                if num == 5:\n",
    "                    print (total_valid, correct_valid)\n",
    "                    valid_accuracy = (100.0 * correct_valid/total_valid)\n",
    "                    print ('valid accuracy: %.2f'% (valid_accuracy))\n",
    "                    scheduler.step(valid_accuracy)\n",
    "        if epoch == 39 or epoch == 49 or epoch ==59:\n",
    "            rcnn.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images).cuda()\n",
    "\n",
    "                outputs = rcnn(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "            print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    torch.save(rcnn,'rcnn.pkl')\n",
    "    rcnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images).cuda()\n",
    "\n",
    "        outputs = rcnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
